---
title: "Лабораторна робота №1"
author: "Юрій Черевач"
format: 
  html:
    toc: true
    toc-location: left
    theme: cosmo
    code-fold: false
execute:
  echo: true
  warning: false
  message: false
jupyter: python3
lang: uk
---

# 1. Моделі та спостереження

- Опишіть приклад простої статистичної моделі для реального процесу (бізнес-ідея, гра тощо).
- Сформулюйте задачу, яку ви хочете вирішити за допомогою статистичного аналізу.

---

Розглянемо процес реагування користувачів на рекламний пост Telegram-каналу. Уявимо, що у кожного користувача є можливість поставити реакцію лише один раз, і розглядатимемо саме реакцію (тобто коли користувач залишає під дописом реакцію у вигляді емодзі).

За таких умов, кожен користувач незалежно приймає рішення. Нехай $X_i$ — результат $i$-го випробування:

$$
X_i = \begin{cases}
1, & \text{успіх (реакція)} \\
0, & \text{невдача (відсутність реакції)}
\end{cases}
$$

Ймовірність успіху: $P(X_i = 1) = \mu$

**Біноміальна модель:**

Випадкова величина $Q$ — загальна кількість реакцій у $n$ незалежних переглядів:

$$
Q = \sum_{i=1}^{n} X_i \sim \text{Binomial}(n, \mu)
$$

## Формулювання задачі

У нас є задача перевірити, чи є справжня конверсія $\mu$ значно вищою за базовий рівень $\mu_0 = 0.015$ (1.5%) на основі спостережень $n = 5000$, $q = 85$. 

> Базовий рівень 1.5% візьмемо як середній показник для каналу без активної промоції.

**Практичне значення:**

- Якщо $\mu > \mu_0$ — рекламний пост ефективний, можна масштабувати кампанію
- Якщо $\mu \le \mu_0$ — потрібно змінити креатив або таргетинг

---

# 2. Перевірка статистичних гіпотез

- Сформулюйте нульову та альтернативну гіпотези.
- Оберіть критерій перевірки.
- Розрахуйте критичне значення на рівні значущості 0.05.

---

## Формулювання гіпотез

Використаємо **правосторонній критерій**:

$$
\begin{aligned}
H_0&: \mu \le 0.015 \quad \text{(конверсія не перевищує базовий рівень)} \\
H_1&: \mu > 0.015 \quad \text{(конверсія вища)}
\end{aligned}
$$

## Вибір критерію перевірки

У виборі критерію орієнтуюся на біноміальний правосторонній критерій.

$Q$ — кількість успіхів, тоді розподіл за $H_0$: $Q \sim \text{Binomial}(5000, 0.015)$

Визначимо критичну область як множину $\{Q \ge C\}$

## Розрахунок критичного значення

Критичне значення розраховується за формулою $C = u_{1-\alpha} + 1$

Знизу наведено python-скрипт, виконавши який ми зможемо отримати критичне значення.

```{python}
#| label: lst-critical-value
#| lst-cap: "Розрахунок критичного значення"

import numpy as np
from scipy.stats import binom

n = 5000                                    #<1>
mu_0 = 0.015                                #<2>
alpha = 0.05                                #<3>

binom_h0 = binom(n, mu_0)                   #<4>
u_1_alpha = binom_h0.ppf(1 - alpha)         #<5>
C = int(u_1_alpha) + 1                      #<6>
prob_critical = 1 - binom_h0.cdf(C - 1)     #<7>

print(f"Параметри: n={n}, μ₀={mu_0}, α={alpha}")
print(f"(1-α)-квантиль: u_(1-α) = {u_1_alpha}")
print(f"Критичне значення: C = {C}")
print(f"P_H₀(Q ≥ {C}) = {prob_critical:.4f}")
```
1. Розмір вибірки (кількість переглядів)
2. Базовий рівень конверсії під нульовою гіпотезою
3. Рівень значущості
4. Створюємо об'єкт біноміального розподілу під $H_0$
5. Обчислюємо $(1-\alpha)$-квантиль розподілу
6. Застосовуємо формулу для критичного значення
7. Перевіряємо ймовірність потрапляння в критичну область

У @lst-critical-value обчислено критичне значення $C = 90$. Це означає, що якщо спостерігатимемо $Q \ge 90$ реакцій, відхилимо $H_0$ на рівні $\alpha = 0.05$.

---

# 3. Використання статистичних функцій

- Напишіть скрипт, який обчислює ймовірність успіху.
- Побудуйте функцію ймовірності та кумулятивну функцію розподілу для цього процесу.
- Знайдіть квантиль для заданого рівня ймовірності (наприклад, 0.95).

---

## Обчислення ймовірності успіху

Перевіримо ймовірність успіху для значення 85 реакцій:
```{python}
#| label: lst-stat-functions
#| lst-cap: "Статистичні функції розподілу"

q_obs = 85                                  #<1>

pmf_q85 = binom_h0.pmf(q_obs)               #<2>
cdf_q84 = binom_h0.cdf(84)                  #<3>
q_095 = binom_h0.ppf(0.95)                  #<4>

print(f"Ймовірність q={q_obs}: P(Q={q_obs}) = {pmf_q85:.6f} ({pmf_q85*100:.2f}%)")
print(f"Накопичена ймовірність: P(Q≤84) = {cdf_q84:.6f} ({cdf_q84*100:.2f}%)")
print(f"0.95-квантиль: u_0.95 = {int(q_095)}")
```
1. Спостережуване значення (кількість реакцій)
2. PMF — ймовірність отримати рівно $q$ успіхів (функція ймовірності дискретного розподілу)
3. CDF — накопичена ймовірність до $q = 84$ (кумулятивна функція розподілу)
4. Квантиль рівня 0.95

У @lst-stat-functions обчислено ключові характеристики розподілу:

- Ймовірність отримати рівно 85 реакцій за $H_0$ становить $\approx 2.3\%$
- З ймовірністю $\ 86.47\%$ спостерігатимемо не більше 84 реакцій
- Квантиль рівня 0.95 дорівнює 89 реакцій

## Побудова PMF та CDF

```{python}
#| label: fig-distributions
#| fig-cap: "PMF та CDF біноміального розподілу під H₀"

import matplotlib.pyplot as plt

k_range = np.arange(0, 150)                #<1>

pmf_values = binom_h0.pmf(k_range)          #<2>
cdf_values = binom_h0.cdf(k_range)          #<3>

fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 6))

# PMF 
ax1.bar(k_range, pmf_values, alpha=0.7, color='steelblue', label='PMF')
ax1.axvline(q_obs, color='red', linestyle='--', linewidth=2.5, label=f'Спостереження q={q_obs}')
ax1.axvline(C, color='green', linestyle=':', linewidth=2.5, label=f'Критичне C={C}')
ax1.set_xlabel('Кількість реакцій (q)', fontsize=12)
ax1.set_ylabel('Ймовірність', fontsize=12)
ax1.set_title('Функція ймовірності (PMF)', fontsize=14)
ax1.legend()
ax1.grid(True, alpha=0.3)

# CDF
ax2.plot(k_range, cdf_values, linewidth=2.5, color='steelblue', label='CDF')
ax2.axvline(q_obs, color='red', linestyle='--', linewidth=2.5, label=f'Спостереження q={q_obs}')
ax2.axvline(C, color='green', linestyle=':', linewidth=2.5, label=f'Критичне C={C}')
ax2.axhline(0.95, color='gray', linestyle=':', alpha=0.6, label='0.95 рівень')
ax2.set_xlabel('Кількість реакцій (q)', fontsize=12)
ax2.set_ylabel('Накопичена ймовірність', fontsize=12)
ax2.set_title('Кумулятивна функція розподілу (CDF)', fontsize=14)
ax2.legend()
ax2.grid(True, alpha=0.3)

plt.tight_layout()
plt.show()
```
1. Діапазон можливих значень для візуалізації
2. Обчислюємо PMF для всіх значень у діапазоні
3. Обчислюємо CDF для всіх значень у діапазоні

На @fig-distributions видно:

- **Ліва панель (PMF):** Найімовірніше значення за $H_0$ — близько 75 реакцій. Спостережене $q = 85$ знаходиться в правому хвості розподілу.
- **Права панель (CDF):** Спостережене значення $q = 85$ перебуває нижче критичного значення $C = 90$, але близько до нього.

---

# 4. Розрахунок p-значення

- Розрахуйте p-значення для перевірки $H_0$.
- Інтерпретуйте результат.

---

## Обчислення p-значення

Для правостороннього тесту використовуємо формулу:

$$
\text{p-value} = P_{H_0}(Q \ge q) = 1 - P_{H_0}(Q \le q-1)
$$

```{python}
#| label: lst-p-value
#| lst-cap: "Розрахунок p-значення"

import numpy as np
from scipy.stats import binom

n = 5000                                    #<1>
mu_0 = 0.015                                #<2>
q_obs = 85                                  #<3>
alpha = 0.05                                #<4>

binom_h0 = binom(n, mu_0)                   #<5>
p_value = 1 - binom_h0.cdf(q_obs - 1)       #<6>

print(f"Параметри тесту:")
print(f"  n = {n}, μ₀ = {mu_0}, q = {q_obs}")
print(f"\nРезультат:")
print(f"  p-value = {p_value:.4f}")
print(f"  α = {alpha}")
print(f"\nВисновок:")
if p_value < alpha:
    print(f"  p-value ({p_value:.4f}) < α ({alpha})")
    print(f"  ❌ Відхиляємо H₀")
    print(f"  Конверсія статистично значущо перевищує базовий рівень {mu_0*100}%")
else:
    print(f"  p-value ({p_value:.4f}) ≥ α ({alpha})")
    print(f"  ✓ Не відхиляємо H₀")
    print(f"  Недостатньо доказів, що конверсія перевищує базовий рівень {mu_0*100}%")
```
1. Розмір вибірки
2. Базовий рівень конверсії під нульовою гіпотезою
3. Спостережуване значення реакцій
4. Рівень значущості
5. Створюємо розподіл під H₀
6. Обчислюємо p-value для правостороннього тесту

## Інтерпретація результату

**p-value ≈ 0.1353** означає, що якби справжня конверсія дорівнювала базовому рівню 1.5% (H₀ істинна), то ймовірність спостерігати 85 або більше реакцій становила б 13.55%.

Оскільки **p-value (0.1355) > α (0.05)**, ми **не відхиляємо** нульову гіпотезу H₀.

# 5. Двосторонні критерії

- Придумайте експеримент, де розподіл випадкової величини не є симетричним і потрібно використовувати двосторонній критерій.
- Напишіть функцію для обчислення p-значення для двостороннього тесту.
- Інтерпретуйте результати тесту.

---

## Експеримент з несиметричним розподілом

**Контекст:** Telegram-канал проводить опитування серед 5000 підписників про задоволеність новою рубрикою. Історично 80% підписників позитивно оцінювали контент каналу.

**Модель:** $Q \sim \text{Binomial}(5000, 0.80)$ під $H_0$

Розподіл **несиметричний**, оскільки $\mu_0 = 0.80$ далеко від 0.5:

- Математичне сподівання: $E[Q] = 5000 \times 0.80 = 4000$
- Лівий хвіст обмежений (мінімум 0), правий хвіст має більше простору (максимум 5000)

**Гіпотези (двосторонній тест):**

$$
\begin{aligned}
H_0&: \mu = 0.80 \quad \text{(рівень задоволеності не змінився)} \\
H_1&: \mu \ne 0.80 \quad \text{(рівень задоволеності змінився)}
\end{aligned}
$$

**Спостереження:** У опитуванні взяли участь всі 5000 підписників, з яких 3850 оцінили рубрику позитивно.

## Функція для обчислення p-значення

```{python}
#| label: lst-two-sided-function
#| lst-cap: "Функція для двостороннього тесту"

import numpy as np
from scipy.stats import binom

def two_sided_pvalue(n, mu_0, q_obs):
    dist = binom(n, mu_0)
    p_obs = dist.pmf(q_obs)
    
    k_values = np.arange(0, n + 1)
    probs = dist.pmf(k_values)
    
    tail_mask = probs <= p_obs
    p_value = np.sum(probs[tail_mask])
    
    return p_value
```

---

## Розрахунок p-значення

```{python}
#| label: lst-two-sided-calculation
#| lst-cap: "Розрахунок двостороннього p-значення"

n = 5000
mu_0 = 0.80
q_obs = 3850
alpha = 0.05

p_value = two_sided_pvalue(n, mu_0, q_obs)

print(f"n = {n}")
print(f"μ₀ = {mu_0}")
print(f"q = {q_obs}")
print(f"Спостережувана конверсія: {q_obs/n:.4f} ({q_obs/n*100:.2f}%)")
print(f"\np-value = {p_value:.6f}")
print(f"α = {alpha}")
print(f"\nРішення: {'Відхиляємо H₀' if p_value < alpha else 'Не відхиляємо H₀'}")
```

---

## Візуалізація розподілу та критичних областей

```{python}
#| label: fig-two-sided
#| fig-cap: "Несиметричний біноміальний розподіл з двосторонніми критичними областями"

import matplotlib.pyplot as plt

dist = binom(n, mu_0)
k_range = np.arange(3700, 4300)

pmf_vals = dist.pmf(k_range)
p_obs = dist.pmf(q_obs)

tail_mask = pmf_vals <= p_obs

fig, ax = plt.subplots(figsize=(12, 6))

ax.bar(k_range, pmf_vals, alpha=0.7, color='steelblue', label='PMF під H₀')
ax.bar(k_range[tail_mask], pmf_vals[tail_mask], alpha=0.9, color='red', 
       label=f'Критичні області (p ≤ {p_obs:.6f})')
ax.axvline(q_obs, color='darkred', linestyle='--', linewidth=2, label=f'Спостереження q={q_obs}')
ax.axvline(n*mu_0, color='green', linestyle=':', linewidth=2, label=f'Очікування μ₀n={n*mu_0:.0f}')

ax.set_xlabel('Кількість позитивних відгуків', fontsize=12)
ax.set_ylabel('Ймовірність', fontsize=12)
ax.set_title('Двосторонній тест для несиметричного розподілу', fontsize=14)
ax.legend()
ax.grid(True, alpha=0.3)

plt.tight_layout()
plt.show()
```

---

## Інтерпретація результату

Отримане **p-значення практично дорівнює 0** (< 0.0001), що значно менше за рівень значущості α = 0.05.

**Висновок:** Ми **відхиляємо нульову гіпотезу** H₀. Рівень задоволеності новою рубрикою статистично значущо відрізняється від історичного показника 80%.

- Спостережувана конверсія становить 77% (3850/5000), що на 3 процентні пункти нижче за очікувану
- При великому розмірі вибірки (n = 5000) навіть невелика різниця стає статистично значущою
- Несиметричність розподілу проявляється у тому, що критична область у лівому хвості (де знаходиться наше спостереження) є більш вузькою порівняно з правим хвостом
